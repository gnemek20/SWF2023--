{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMGhfIBUMig98dNxm6dBnal"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"t3ecE0xCfa1F"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["from tensorflow.python.ops.gen_data_flow_ops import barrier_ready_size_eager_fallback\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Input, Activation, Flatten\n","from tensorflow.keras.layers import BatchNormalization,Add,Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import LeakyReLU, ReLU, Conv2D, MaxPooling2D, BatchNormalization, Conv2DTranspose, UpSampling2D, concatenate\n","from tensorflow.keras import callbacks\n","from tensorflow.keras import backend as K\n","from tensorflow.keras import layers"],"metadata":{"id":"dxkfAiA8fnO2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def UNet(pretrained_weights = None,input_size = (128,128,3)):\n","    inp = Input(input_size)\n","\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inp)\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","    drop4 = Dropout(0.5)(conv4)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","    drop5 = Dropout(0.5)(conv5)\n","\n","    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","    merge6 = concatenate([drop4,up6], axis = 3)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","\n","    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","    merge7 = concatenate([conv3,up7], axis = 3)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","\n","    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","    merge8 = concatenate([conv2,up8], axis = 3)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","\n","    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","    merge9 = concatenate([conv1,up9], axis = 3)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv10 = Conv2D(3, 1, activation = 'sigmoid')(conv9)\n","\n","    model = Model(inputs = inp, outputs=[conv10])\n","\n","    return model"],"metadata":{"id":"ITTdhdaufqDd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from glob import glob\n","from PIL import Image\n","import cv2\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from ultralytics import YOLO\n","\n","def identity_loss(y_true, y_pred):\n","  loss = tf.reduce_mean(tf.abs(y_true - y_pred))\n","  return loss\n","\n","seg_model = YOLO(\"/content/drive/MyDrive/save_your_biometric_informations/runs/segment/train5/weights/best.pt\")\n","\n","data_path = glob(\"/content/drive/MyDrive/save_your_biometric_informations/*/images/*.jpg\")\n","# data_path = ['/content/drive/MyDrive/save_your_biometric_informations/runs/영석1.jpg']\n","batch_size = 32\n","model = UNet()\n","model.compile(optimizer=Adam(learning_rate=3e-4), loss='binary_crossentropy')\n","dataset = list()\n","\n","for data in tqdm(data_path):\n","  image = np.array(Image.open(data))\n","  h, w, _ = image.shape\n","  results = seg_model.predict(data)\n","\n","  for result in results:\n","    masks = result.masks\n","    boxes = result.boxes\n","  if masks is not None:\n","    for mask, box in zip(masks.data, boxes.data):\n","      mask = cv2.resize(np.array(mask.cpu()).astype(np.uint8), dsize=(w, h), interpolation=cv2.INTER_CUBIC)\n","      bbox = int(box[1]), int(box[3]), int(box[0]), int(box[2])\n","      mask = mask[bbox[0]:bbox[1], bbox[2]:bbox[3]]\n","      sliced_img = image[bbox[0]:bbox[1], bbox[2]:bbox[3]]\n","\n","      masked_img1 = mask * sliced_img[:, :, 0]\n","      masked_img2 = mask * sliced_img[:, :, 1]\n","      masked_img3 = mask * sliced_img[:, :, 2]\n","      masked_img = cv2.merge((masked_img1, masked_img2, masked_img3))\n","\n","      masked_img = cv2.resize(masked_img, dsize=(128, 128), interpolation=cv2.INTER_CUBIC)\n","      masked_img = np.array(masked_img) / 255.0\n","\n","      dataset.append(masked_img)\n","\n","train_dataset = tf.data.Dataset.from_tensor_slices((dataset, dataset)).shuffle(buffer_size=1000).batch(batch_size)\n","\n","data_augmentation = tf.keras.Sequential([\n","  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n","  layers.experimental.preprocessing.RandomRotation(0.2),\n","])"],"metadata":{"id":"3vB70a4Wfs97"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = UNet()\n","model.compile(optimizer=Adam(learning_rate=3e-4), loss='binary_crossentropy')"],"metadata":{"id":"wJycVoe_f5RD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.fit(train_dataset, epochs=50, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"NumGjJ6Lf8zd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 이미지 변조 실험\n","\n","seg_model = YOLO(\"/content/drive/MyDrive/save_your_biometric_informations/runs/segment/train5/weights/best.pt\")\n","\n","data = '/content/drive/MyDrive/save_your_biometric_informations/runs/영석1.jpg'\n","image = np.array(Image.open(data))\n","h, w, _ = image.shape\n","results = seg_model.predict(data)\n","\n","for result in results:\n","  masks = result.masks\n","  boxes = result.boxes\n","\n","if masks is not None:\n","  for mask, box in zip(masks.data, boxes.data):\n","    mask = cv2.resize(np.array(mask.cpu()).astype(np.uint8), dsize=(w, h), interpolation=cv2.INTER_CUBIC)\n","    bbox = int(box[1]), int(box[3]), int(box[0]), int(box[2])\n","    mask = mask[bbox[0]:bbox[1], bbox[2]:bbox[3]]\n","    sliced_img = image[bbox[0]:bbox[1], bbox[2]:bbox[3]]\n","\n","    masked_img1 = mask * sliced_img[:, :, 0]\n","    masked_img2 = mask * sliced_img[:, :, 1]\n","    masked_img3 = mask * sliced_img[:, :, 2]\n","    masked_img = cv2.merge((masked_img1, masked_img2, masked_img3))\n","\n","    masked_img = cv2.resize(masked_img, dsize=(128, 128), interpolation=cv2.INTER_CUBIC)\n","    masked_img = np.array(masked_img) / 255.0\n","\n","    output = model.predict(masked_img.reshape(1, 128, 128, 3))\n","    output = cv2.resize(output[0], dsize=(bbox[3]-bbox[2], bbox[1]-bbox[0]), interpolation=cv2.INTER_CUBIC)\n","\n","    sliced_img = image[bbox[0]:bbox[1], bbox[2]:bbox[3]]\n","\n","    mask = mask ^ True\n","    masked_img1 = mask * sliced_img[:, :, 0]\n","    masked_img2 = mask * sliced_img[:, :, 1]\n","    masked_img3 = mask * sliced_img[:, :, 2]\n","    masked_img = cv2.merge((masked_img1, masked_img2, masked_img3))\n","\n","    output = np.add(masked_img, (output * 255).astype(np.int8)).astype(np.uint8)\n","    image[bbox[0]:bbox[1], bbox[2]:bbox[3]] = output\n","\n","  plt.imshow(image)\n","  plt.show()"],"metadata":{"id":"xa_1dKRAgA6L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pathlib\n","\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","\n","tflite_models_dir = pathlib.Path(\"./\")\n","tflite_models_dir.mkdir(exist_ok=True, parents=True)\n","\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","tflite_quant_model = converter.convert()\n","tflite_model_quant_file = tflite_models_dir/\"unet_quant.tflite\"\n","tflite_model_quant_file.write_bytes(tflite_quant_model)"],"metadata":{"id":"DxW7tUewgHJF"},"execution_count":null,"outputs":[]}]}